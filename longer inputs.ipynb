{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting whether or not to meet again from three-word description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('processed_data hand-corrected.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good-humoured, creative, curious.</td>\n",
       "      <td>Yeah, I’d definitely go for another drink next time he’s in London. But only if his dog Luna can come too.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bubbly, fun, intelligent.</td>\n",
       "      <td>As friends, absolutely.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enthusiastic, energetic, musical.</td>\n",
       "      <td>Yes. We spoke of it, as she does come to London and I will be house hunting in the north over the next year.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smart, American, sweet.</td>\n",
       "      <td>Hopefully. We talked about it and exchanged numbers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lively, open and vivacious.</td>\n",
       "      <td>I would love the chance to. We talked of visiting the Winslow Homer exhibition at the National Gallery but we did not exchange contact details. Silly me – or was it deliberate on Nicole’s part? Only time will tell.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>NaN</td>\n",
       "      <td>She didn't seem that interested, so I doubt it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I didn't detect any chemistry and we didn't swap numbers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes - for a drink and see how things developed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes. It would be interesting to be in our own environment, where we could have a bit more craic. I reckon we could have a laugh.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes, definitely - as friends for the time being. We got on really well, so it was a good start.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1438 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text  \\\n",
       "0    Good-humoured, creative, curious.   \n",
       "1            Bubbly, fun, intelligent.   \n",
       "2    Enthusiastic, energetic, musical.   \n",
       "3              Smart, American, sweet.   \n",
       "4          Lively, open and vivacious.   \n",
       "..                                 ...   \n",
       "714                                NaN   \n",
       "715                                NaN   \n",
       "716                                NaN   \n",
       "717                                NaN   \n",
       "718                                NaN   \n",
       "\n",
       "                                                                                                                                                                                                                     result  \n",
       "0                                                                                                                Yeah, I’d definitely go for another drink next time he’s in London. But only if his dog Luna can come too.  \n",
       "1                                                                                                                                                                                                   As friends, absolutely.  \n",
       "2                                                                                                              Yes. We spoke of it, as she does come to London and I will be house hunting in the north over the next year.  \n",
       "3                                                                                                                                                                      Hopefully. We talked about it and exchanged numbers.  \n",
       "4    I would love the chance to. We talked of visiting the Winslow Homer exhibition at the National Gallery but we did not exchange contact details. Silly me – or was it deliberate on Nicole’s part? Only time will tell.  \n",
       "..                                                                                                                                                                                                                      ...  \n",
       "714                                                                                                                                                                         She didn't seem that interested, so I doubt it.  \n",
       "715                                                                                                                                                               I didn't detect any chemistry and we didn't swap numbers.  \n",
       "716                                                                                                                                                                         Yes - for a drink and see how things developed.  \n",
       "717                                                                                        Yes. It would be interesting to be in our own environment, where we could have a bit more craic. I reckon we could have a laugh.  \n",
       "718                                                                                                                        Yes, definitely - as friends for the time being. We got on really well, so it was a good start.   \n",
       "\n",
       "[1438 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_a = df.rename(columns={'A_describe_X_in_three_words': 'text', 'A_would_you_meet_again': 'result'})[['text', 'result']]\n",
    "df_b = df.rename(columns={'B_describe_X_in_three_words': 'text', 'B_would_you_meet_again': 'result'})[['text', 'result']]\n",
    "new_df = pd.concat([df_a, df_b], axis=0)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df.dropna().reset_index(drop=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.loc[:, 'bool'] = new_df.loc[:, 'score'] >= 8\n",
    "new_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from-scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "y = tensor(new_df['bool'].values).float()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = tensor(vectorizer.fit_transform(new_df['text']).toarray()).float()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names_out()[X[0].numpy().nonzero()])\n",
    "new_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# torch.manual_seed(0)\n",
    "n_coeffs = X.shape[1]\n",
    "coeffs = torch.rand(n_coeffs, 1) - 0.5\n",
    "coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pred(X, coeffs):\n",
    "    return torch.sigmoid(X @ coeffs)\n",
    "\n",
    "def calc_loss(pred, y):\n",
    "    return torch.abs(pred - y).mean()\n",
    "\n",
    "def init_coeffs():\n",
    "    return (torch.rand(n_coeffs, 1)*0.1).requires_grad_()\n",
    "\n",
    "def update_coeffs(coeffs, lr):\n",
    "    coeffs.sub_(lr * coeffs.grad)\n",
    "    coeffs.grad.zero_()\n",
    "\n",
    "def accuracy(coeffs, X, y):\n",
    "    preds = calc_pred(X, coeffs)\n",
    "    return (y.bool() == (preds > 0.5)).float().mean()\n",
    "\n",
    "def one_epoch(coeffs, lr, X, y):\n",
    "    loss = calc_loss(calc_pred(X, coeffs), y)\n",
    "    loss.backward()\n",
    "    with torch.no_grad(): update_coeffs(coeffs, lr)\n",
    "    print(f\"Loss: {loss:.4f}, Accuracy {accuracy(coeffs, X, y):.4f}\", end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import RandomSplitter\n",
    "trn_split, val_split = RandomSplitter()(new_df) # can set seed\n",
    "X_train, X_val = X[trn_split], X[val_split]\n",
    "y_train, y_val = y[trn_split][:, None], y[val_split][:, None]\n",
    "len(y_train), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs=30, lr=0.1, X=X_train, y=y_train):\n",
    "    # torch.manual_seed(0)\n",
    "    coeffs = init_coeffs()\n",
    "    for i in range(epochs):\n",
    "        print(f\"Epoch {i+1}: \", end='')\n",
    "        one_epoch(coeffs, lr, X, y)\n",
    "        print()\n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = train_model(lr=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_coeffs():\n",
    "    return dict(zip(vectorizer.get_feature_names_out(), coeffs.requires_grad_(False).numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_df = pd.DataFrame.from_dict(show_coeffs(), orient='index', columns=['weight'])\n",
    "weights_df.sort_values('weight', ascending=False, inplace=True)\n",
    "weights_df.reset_index(inplace=True)\n",
    "weights_df.rename(columns={'index': 'word'}, inplace=True)\n",
    "weights_df.to_excel('weights.xlsx', index=False)\n",
    "weights_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = calc_pred(X_val, coeffs)\n",
    "results = y_val.bool() == (val_preds > 0.5)\n",
    "results.float().mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import *\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(new_df)\n",
    "ds = ds.rename_column('bool', 'labels')\n",
    "ds = ds.cast_column('labels', Value('float32'))\n",
    "dds = ds.train_test_split(seed=2005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'microsoft/deberta-v3-small'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, padding=True)\n",
    "dds = dds.map(tokenize_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load('accuracy')\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.round(logits)\n",
    "    return metric.compute(predictions=preds, references=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
    "\n",
    "bs = 16\n",
    "lr = 1e-4\n",
    "epochs = 5\n",
    "args = TrainingArguments('outputs', learning_rate=lr, per_device_train_batch_size=bs, per_device_eval_batch_size=bs, num_train_epochs=epochs,\n",
    "                         evaluation_strategy='epoch', save_strategy='epoch', weight_decay=0.01, warmup_ratio=0.1, load_best_model_at_end=True, metric_for_best_model='accuracy'\n",
    "                        ) # auto_find_batch_size? (requires pip install accelerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dds['train'],\n",
    "    eval_dataset=dds['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-small')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('outputs/checkpoint-117')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis', model='outputs/checkpoint-117', tokenizer=tokenizer) # you can infer the task if the model hasn't been fine-tuned, I think\n",
    "\n",
    "text = \"nice\"\n",
    "classifier(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"funny, interesting, fun\", return_tensors=\"pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d267c39223eb2a444f7b51aaabb83d648413f5a98be4d3157e2d2b8f4fd61ed3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
